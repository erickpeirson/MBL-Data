{
 "metadata": {
  "name": "",
  "signature": "sha256:8640fb86fdf34330ae2318c2ce66a8c01867e8b8a2fc708a25004d2ea42591ce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from openpyxl import load_workbook\n",
      "from unidecode import unidecode\n",
      "import matplotlib.pyplot as plt\n",
      "from collections import Counter\n",
      "import re\n",
      "import string\n",
      "import Levenshtein\n",
      "import time\n",
      "from uuid import uuid4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def strip_punctuation(s):\n",
      "    exclude = set(string.punctuation)\n",
      "    s = ''.join(ch for ch in s if ch not in exclude)\n",
      "    return s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'{0}'.format(uuid4())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 367,
       "text": [
        "'d96ed907-d0b4-4b8d-8ca3-3835681c37ae'"
       ]
      }
     ],
     "prompt_number": 367
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load course and investigator data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "courselist_wb = load_workbook('/Users/bpeirson/Desktop/MBL Data/MBL COURSE LIST.xlsx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "investigators_wb = load_workbook('/Users/bpeirson/Desktop/MBL Data/MBL INVESTIGATOR LIST.xlsx')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coursedata = []\n",
      "for sheetname in courselist_wb.get_sheet_names():\n",
      "    sheet = courselist_wb.get_sheet_by_name(sheetname)\n",
      "    header_row = sheet.rows[0]\n",
      "    data_rows = sheet.rows[1:]\n",
      "    for row in data_rows:\n",
      "        datum = {'year':int(sheetname)}\n",
      "        for c in xrange(len(header_row)):\n",
      "            val = row[c].value\n",
      "            header = header_row[c].value\n",
      "            if val is not None and header is not None:\n",
      "                datum[header] = val\n",
      "        coursedata.append(datum)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "investigatorsdata = []\n",
      "for sheetname in investigators_wb.get_sheet_names():\n",
      "    sheet = investigators_wb.get_sheet_by_name(sheetname)\n",
      "    header_row = sheet.rows[0]\n",
      "    data_rows = sheet.rows[1:]\n",
      "    lastrole = None\n",
      "    lastsubject = None\n",
      "    for row in data_rows:\n",
      "        datum = {'year':int(sheetname)}\n",
      "        for c in xrange(len(header_row)):\n",
      "            val = row[c].value\n",
      "            header = header_row[c].value\n",
      "            if header in ('Independent or Beginner', 'Independent or Beginner?'):\n",
      "                header = 'Role'\n",
      "            \n",
      "            if val is not None and header is not None:\n",
      "                datum[header] = val\n",
      "            elif header == 'Role' and val is None:\n",
      "                val = lastrole\n",
      "                datum[header] = val\n",
      "            elif header == 'Subject' and val is None:\n",
      "                val = lastsubject\n",
      "                datum[header] = val\n",
      "                \n",
      "            if header == 'Role' and val is not None:\n",
      "                lastrole = unicode(val)\n",
      "            if header == 'Subject' and val is not None:\n",
      "                lastsubject = unicode(val)\n",
      "        investigatorsdata.append(datum)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "investigatorsdata[8092]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 341,
       "text": [
        "{u'Affiliation': u' College of the City of New York.',\n",
        " u'First Name': u' LEONARD P.',\n",
        " u'Last Name': u'SAYLES',\n",
        " u'Position': u' Assistant Professor',\n",
        " 'Role': u'Independent',\n",
        " 'year': 1940}"
       ]
      }
     ],
     "prompt_number": 341
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(coursedata), len(investigatorsdata), len(coursedata) + len(investigatorsdata)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "47813 37520 85333\n"
       ]
      }
     ],
     "prompt_number": 248
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Normalize course names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "course_names = set([])\n",
      "f_course_names = Counter()\n",
      "for datum in coursedata:\n",
      "    try:\n",
      "        name = unidecode(datum['Course Name'].strip().lower().replace('&', 'and').replace('1', 'i').replace('2', 'ii'))\n",
      "        course_names.add(name)\n",
      "        f_course_names[name] += 1\n",
      "    except KeyError:\n",
      "        pass\n",
      "print len(course_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "158\n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distances = []\n",
      "course_names_list = list(course_names)\n",
      "for i in xrange(len(course_names_list)):\n",
      "    for j in xrange(i+1, len(course_names_list)):\n",
      "        a = course_names_list[i]\n",
      "        b = course_names_list[j]\n",
      "        d = levenshtein(a,b)\n",
      "        dnorm = float(d)/mean([float(len(a)), float(len(b))])\n",
      "        distances.append( (i,j,d, dnorm) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for d in distances:\n",
      "    if d[3] < 0.17:\n",
      "        a = course_names_list[d[0]]\n",
      "        b = course_names_list[d[1]]\n",
      "        dnorm = d[3]\n",
      "\n",
      "        print d[3], d[2]\n",
      "        print f_course_names[a], '\\t', a\n",
      "        print f_course_names[b], '\\t', b   \n",
      "        print '-'*40"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0109289617486 1\n",
        "175 \tphysiology: modern cell biology using microscopic, biochemical and computational approaches\n",
        "84 \tphysiology: modern cell biology using microscopic, biochemical, and computational approaches\n",
        "----------------------------------------\n",
        "0.0555555555556 1\n",
        "39 \toptimal microscopy\n",
        "178 \toptical microscopy\n",
        "----------------------------------------\n",
        "0.145454545455 8\n",
        "37 \tspines--summer program in neuroscience, ethics and survival\n",
        "166 \tsummer program in neuroscience, ethics and survival\n",
        "----------------------------------------\n",
        "0.0759493670886 3\n",
        "35 \tsmall computers in biomedical research\n",
        "19 \tsmall computers in biomedical research, i\n",
        "----------------------------------------\n",
        "0.1 4\n",
        "35 \tsmall computers in biomedical research\n",
        "18 \tsmall computers in biomedical research, ii\n",
        "----------------------------------------\n",
        "0.1 4\n",
        "115 \tphysiology: cell and molecular biology\n",
        "368 \tphysiology: cellular and molecular biology\n",
        "----------------------------------------\n",
        "0.0240963855422 1\n",
        "19 \tsmall computers in biomedical research, i\n",
        "18 \tsmall computers in biomedical research, ii\n",
        "----------------------------------------\n",
        "0.0307692307692 1\n",
        "46 \tnasa planetary biology inernship\n",
        "15 \tnasa planetary biology internship\n",
        "----------------------------------------\n",
        "0.0240963855422 1\n",
        "65 \tparthogenesis of neuroimmunologic diseases\n",
        "489 \tpathogenesis of neuroimmunologic diseases\n",
        "----------------------------------------\n",
        "0.041958041958 3\n",
        "54 \tbasic immunohistochemical techniques in tissue sections and whole mounts\n",
        "19 \tbasic immunocytochemical techniques in tissue sections and whole mounts\n",
        "----------------------------------------\n",
        "0.06 3\n",
        "40 \tsummer program in neuroscience, ethics $ survival\n",
        "166 \tsummer program in neuroscience, ethics and survival\n",
        "----------------------------------------\n",
        "0.1 2\n",
        "451 \tmedical informatics\n",
        "129 \tmedical informatics i\n",
        "----------------------------------------\n",
        "0.146341463415 3\n",
        "451 \tmedical informatics\n",
        "130 \tmedical informatics ii\n",
        "----------------------------------------\n",
        "0.146341463415 3\n",
        "451 \tmedical informatics\n",
        "94 \tbiomedical informatics\n",
        "----------------------------------------\n",
        "0.0175438596491 1\n",
        "549 \toptimal microscopy and imaging in the biomedical sciences\n",
        "155 \toptical microscopy and imaging in the biomedical sciences\n",
        "----------------------------------------\n",
        "0.046511627907 1\n",
        "129 \tmedical informatics i\n",
        "130 \tmedical informatics ii\n",
        "----------------------------------------\n",
        "0.133333333333 3\n",
        "129 \tmedical informatics i\n",
        "232 \tbiomedical informatics i\n",
        "----------------------------------------\n",
        "0.127659574468 3\n",
        "312 \tbiomedical informatics ii\n",
        "130 \tmedical informatics ii\n",
        "----------------------------------------\n",
        "0.127659574468 3\n",
        "312 \tbiomedical informatics ii\n",
        "94 \tbiomedical informatics\n",
        "----------------------------------------\n",
        "0.0408163265306 1\n",
        "312 \tbiomedical informatics ii\n",
        "232 \tbiomedical informatics i\n",
        "----------------------------------------\n",
        "0.136363636364 3\n",
        "26 \tcomparative physiology\n",
        "4 \tcomparative psychology\n",
        "----------------------------------------\n",
        "0.150537634409 7\n",
        "13 \tadvanced workshop on recombinant dna methodology\n",
        "21 \tbasic workshop on recombinant dna methodology\n",
        "----------------------------------------\n",
        "0.0869565217391 2\n",
        "94 \tbiomedical informatics\n",
        "232 \tbiomedical informatics i\n",
        "----------------------------------------\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The course_map handles typographical errors in the dataset. There are remarkably\n",
      "#  few typos. We specify the appropriate spellings manually, below.\n",
      "course_map = { \n",
      "    'optimal microscopy': 'optical microscopy',\n",
      "    'optimal microscopy and imaging in the biomedical sciences': 'optical microscopy and imaging in the biomedical sciences',\n",
      "    'nasa planetary biology inernship': 'nasa planetary biology internship',\n",
      "    'summer program in neuroscience, ethics $ survival': 'summer program in neuroscience, ethics and survival',\n",
      "    'spines--summer program in neuroscience, ethics and survival': 'summer program in neuroscience, ethics and survival',\n",
      "    'physiology: modern cell biology using microscopic, biochemical and computational approaches': 'physiology: modern cell biology using microscopic, biochemical, and computational approaches',\n",
      "    'physiology: cell and molecular biology': 'physiology: cellular and molecular biology',\n",
      "    'parthogenesis of neuroimmunologic diseases': 'pathogenesis of neuroimmunologic diseases',\n",
      "}\n",
      "print len(course_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8\n"
       ]
      }
     ],
     "prompt_number": 318
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If two courses share the same name, then we generally consider them to belong to the \n",
      "#  same course group. For example, the 'Ecology' course in 1934 (say) belongs to the\n",
      "#  same group (or series) as the 'Ecology' course in 1965 (say).\n",
      "#\n",
      "# In some cases, however, courses with slightly (or perhaps very) different names\n",
      "#  may belong to the same group. For example, an Embryology course might have some\n",
      "#  subtitle, like: \"Embryology: Some great new theme for this course\". Or they might\n",
      "#  be numbered, like \"Biomedical informatics I\" and \"Biomedical informatics II\".\n",
      "#\n",
      "# The coursegroup_map handles the latter cases. Keys are specific course names that\n",
      "#  occur in the dataset, and values are the group names that should be used.\n",
      "#  Some of these mappings are given manually, based on inspection of the dataset.\n",
      "#  Other mappings are generated by looking for colons (':') in course names; the\n",
      "#  part of the name before the colon is assumed to be the proper group name.\n",
      "\n",
      "coursegroup_map = { \n",
      "    'small computers in biomedical research, i': 'small computers in biomedical research',\n",
      "    'small computers in biomedical research, ii': 'small computers in biomedical research',\n",
      "    'medical informatics': 'biomedical informatics',\n",
      "    'medical informatics i': 'biomedical informatics',\n",
      "    'medical informatics ii': 'biomedical informatics',\n",
      "    'biomedical informatics i': 'biomedical informatics',\n",
      "    'biomedical informatics ii': 'biomedical informatics',\n",
      "    'advanced workshop on recombinant dna methodology': 'workshop on recombinant dna methodology',\n",
      "    'basic workshop on recombinant dna methodology': 'workshop on recombinant dna methodology',\n",
      "}\n",
      "\n",
      "for cname in list(course_names):   # Here we look for course names with subtitles,\n",
      "    parts = cname.split(':')       #  characterized by a colon (':') in their names.\n",
      "    if len(parts) > 1:\n",
      "        coursegroup_map.update({cname:parts[0]})\n",
      "print len(coursegroup_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "32\n"
       ]
      }
     ],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize_coursename(cname):\n",
      "    cname = unidecode(cname).lower().strip()\n",
      "    \n",
      "    if cname in course_map:\n",
      "        cname = course_map[cname]\n",
      "    if cname in coursegroup_map:\n",
      "        group = coursegroup_map[cname]\n",
      "    else:\n",
      "        group = cname\n",
      "    return cname, group"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "course_ids = {}\n",
      "def get_course_uri(cname):\n",
      "    if cname not in course_ids:\n",
      "        uri = 'http://history.archives.mbl.edu/concepts/course/{0}'.format(uuid4())  \n",
      "        course_ids[cname] = uri\n",
      "    else:\n",
      "        uri = course_ids[cname]\n",
      "    return uri"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 394
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coursegroup_ids = {}\n",
      "def get_coursegroup_uri(coursegroup):\n",
      "    if coursegroup not in coursegroup_ids:\n",
      "        uri = 'http://history.archives.mbl.edu/concepts/coursegroup/{0}'.format(uuid4())  \n",
      "        coursegroup_ids[coursegroup] = uri\n",
      "    else:\n",
      "        uri = coursegroup_ids[coursegroup]\n",
      "    return uri"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 395
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Normalize personal names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "person_ids = {}   # Name -> URI"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 383
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "personal_names = set([])\n",
      "f_personal_names = Counter()\n",
      "personal_affiliations = {}\n",
      "for datum in coursedata + investigatorsdata:\n",
      "    try:\n",
      "        lastname = unidecode(unicode(datum['Last Name']).strip().lower().replace('.',''))\n",
      "        firstname = unidecode(unicode(datum['First Name']).strip().lower())\n",
      "        firstname = ' '.join([ n.strip(' ') for n in re.split('\\.|\\W+', firstname) if n != '' ]).strip().replace('.','')\n",
      "        affiliations = normalized_institutions(datum['Affiliation'])    # Returns a list.\n",
      "        name = (lastname, firstname)\n",
      "        personal_names.add(name)\n",
      "        f_personal_names[name] += 1\n",
      "        \n",
      "        if name not in personal_affiliations:\n",
      "            personal_affiliations[name] = set([])\n",
      "        for affiliation in affiliations:  \n",
      "            personal_affiliations[name].add(affiliation)\n",
      "    except KeyError:\n",
      "        pass\n",
      "    except AttributeError:\n",
      "        print datum['Last Name']\n",
      "print len(personal_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "30006\n"
       ]
      }
     ],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "personal_names_list = list(personal_names)\n",
      "N_names = len(personal_names)\n",
      "by_last = {}\n",
      "for i in xrange(N_names):\n",
      "    lastname, firstname = personal_names_list[i]\n",
      "    if lastname not in by_last:\n",
      "        by_last[lastname] = set([])\n",
      "    by_last[lastname].add(firstname)    # The surname of A is identical to the surname of B"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "person_map = {}\n",
      "for last, firsts in by_last.iteritems():    # We assume that surnames are not misspelled.\n",
      "    N_firsts = len(firsts)                  #  This is not strictly true, but it is not\n",
      "    if N_firsts > 1:                        #  quite clear how to proceed otherwise.\n",
      "        lfirsts = list(firsts)              # Consider cases in which two names, I and J,\n",
      "        for i in xrange(N_firsts):          #  have a common surname.\n",
      "            iname = lfirsts[i]\n",
      "            inames = iname.split(' ')\n",
      "            iinits = [f[0] for f in inames ]\n",
      "            \n",
      "            for j in xrange(i+1, N_firsts):     \n",
      "                jname = lfirsts[j]\n",
      "                jnames = jname.split(' ')\n",
      "                jinits = [f[0] for f in jnames ]\n",
      "\n",
      "                # For each such pair, I and J, we compare the X parts of their forenames,\n",
      "                #  where X is the minimum number of forename parts for I and J.\n",
      "                match = True               \n",
      "                for x in xrange(min( [len(inames), len(jnames)] )):\n",
      "                    # If the x part if either forename is an initial, we evaluate\n",
      "                    #  only the first character of the two parts.\n",
      "                    if len(inames[x]) == 1 or len(jnames[x]) == 1:\n",
      "                        if iinits[x] != jinits[x]:\n",
      "                            match = False\n",
      "                    # Otherwise, the x part of the two forenames must be identical.\n",
      "                    else:\n",
      "                        if inames[x] != jnames[x]:\n",
      "                            match = False\n",
      "                if match:     \n",
      "                    # If the forenames of I and J match, as described above, we check\n",
      "                    # to see whether they share at least one institutional affiliation.\n",
      "                    shared = personal_affiliations[(last, iname)] & personal_affiliations[(last, jname)]\n",
      "                    if len(shared) > 0:\n",
      "                        # If they share at least one institutional affiliation, then\n",
      "                        #  we believe that I and J both refer to the same person.\n",
      "                        if len(iname) > len(jname):    # Use the longest name (most complete).\n",
      "                            key = jname\n",
      "                            alt = iname\n",
      "                        else:\n",
      "                            key = iname\n",
      "                            alt = jname\n",
      "                        if (last, alt) in person_map:\n",
      "                            top = False\n",
      "                            while not top:\n",
      "                                try:\n",
      "                                    alt = person_map[(last,alt)][1]\n",
      "                                except KeyError:\n",
      "                                    top = True\n",
      "                        person_map[(last, key)] = (last, alt)      \n",
      "                        \n",
      "    # If the conditions above are not satisfied, then we lack sufficient evidence to\n",
      "    #  assert that the names I and J refer to the same person.\n",
      "print len(person_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "845\n"
       ]
      }
     ],
     "prompt_number": 378
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalized_person(last, first):\n",
      "    \"\"\"\n",
      "    Generates a normalized representation of a personal name.\n",
      "    \"\"\"\n",
      "    lastname = unidecode(unicode(last)\n",
      "                                 .strip()\n",
      "                                 .lower()\n",
      "                                 .replace('.',''))\n",
      "    firstname = unidecode(unicode(first)\n",
      "                                  .strip()\n",
      "                                  .lower())\n",
      "    firstname = ' '.join([ n.strip(' ') for n \n",
      "                          in re.split('\\.|\\W+', firstname) \n",
      "                          if n != '' ]).strip().replace('.','')    \n",
      "            \n",
      "    name = (lastname, firstname)\n",
      "    if name in person_map:\n",
      "        normed_name = person_map[name]\n",
      "    else:\n",
      "        normed_name = name\n",
      "    if normed_name not in person_ids:\n",
      "        uri = 'http://history.archives.mbl.edu/concepts/person/{0}'.format(uuid4())\n",
      "        person_ids[normed_name] = uri\n",
      "    else:\n",
      "        uri = person_ids[normed_name]\n",
      "    return normed_name, uri"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 384
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "for datum in investigatorsdata[0:10]:\n",
      "    if 'Last Name' in datum and 'First Name' in datum:\n",
      "        print normalized_person(datum['Last Name'], datum['First Name'])\n",
      "    i += 1\n",
      "print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('gardiner', 'edward g')\n",
        "('jordan', 'edwin o')\n",
        "('washburn', 'f l')\n",
        "('clapp', 'cornelia maria')\n",
        "(\"o'grady\", 'marcella i')\n",
        "('harris', 'helen torrey')\n",
        "('mulford', 'isabel')\n",
        "('ayers', 'howard')\n",
        "('farlow', 'w g')\n",
        "('gardiner', 'edward g')\n",
        "10\n"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Normalize institution names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "institution_names = set([])\n",
      "f_institution_names = Counter()\n",
      "for datum in coursedata + investigatorsdata:\n",
      "    try:\n",
      "        affs = unidecode(unicode(datum['Affiliation'])\n",
      "                             .strip()\n",
      "                             .lower()\n",
      "                             .replace('.','')\n",
      "                             .replace(',','')\n",
      "                             .replace('&', 'and')\n",
      "                             .replace('-', ' '))\n",
      "        for aff in affs.split('/'):\n",
      "            aff = strip_punctuation(aff.strip()).replace('  ',' ')\n",
      "            aff = ' '.join([ word for word in aff.split(' ') if word != 'the'])\n",
      "            institution_names.add(aff)\n",
      "            f_institution_names[aff] += 1\n",
      "    except KeyError:\n",
      "        pass\n",
      "print len(institution_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6171\n"
       ]
      }
     ],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "institution_distances = []\n",
      "institution_names_list = list(institution_names)\n",
      "for i in xrange(len(institution_names_list)):\n",
      "    for j in xrange(i+1, len(institution_names_list)):\n",
      "        a = institution_names_list[i]\n",
      "        b = institution_names_list[j]\n",
      "        d = Levenshtein.distance(a,b)\n",
      "        dnorm = float(d)/mean([float(len(a)), float(len(b))])\n",
      "        institution_distances.append( (i,j,d, dnorm) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 250
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "institutions_lookup = {}\n",
      "for d in institution_distances:\n",
      "    if d[3] < 0.1 and d[2] < 4:\n",
      "        a = institution_names_list[d[0]]\n",
      "        b = institution_names_list[d[1]]\n",
      "        f_a = f_institution_names[a]\n",
      "        f_b = f_institution_names[b]\n",
      "        \n",
      "        if f_a > f_b:\n",
      "            key = a\n",
      "            alt = b\n",
      "            f_key = f_a\n",
      "            f_alt = f_b\n",
      "        else:\n",
      "            key = b\n",
      "            alt = a\n",
      "            f_key = f_b\n",
      "            f_alt = f_a\n",
      "        \n",
      "        if alt in institutions_lookup:\n",
      "            f_m = f_institution_names[institutions_lookup[alt]]\n",
      "            if f_key > f_m:\n",
      "                institutions_lookup[alt] = key\n",
      "        else:\n",
      "            institutions_lookup[alt] = key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "institution_ids = {\n",
      "    'Marine Biological Laboratory': 'http://history.archives.mbl.edu/concepts/institution/{0}'.format(uuid4()),\n",
      "}   # Institution -> URI\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 388
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalized_institutions(inames):\n",
      "    \"\"\"\n",
      "    Generates a normalized representation of an institutional name.\n",
      "    \"\"\"\n",
      "    anames = []\n",
      "    affs = unidecode(unicode(inames)            # The value of the 'Affiliation' field is\n",
      "                         .strip()               #  stripped padding whitespace (e.g. spaces),\n",
      "                         .lower()               #  and converted to lowercase.\n",
      "                         .replace('&', 'and')   # Ampersands are converted to 'and', and\n",
      "                         .replace('-', ' '))    #  hyphens are interpreted as spaces.\n",
      "                                                # The 'Affiliation' field can contain multiple\n",
      "    for aff in affs.split('/'):                 #  institutions, separated by a slash ('/').\n",
      "        # All punctuation is removed, and double-spaces are converted to single.     \n",
      "        aff = strip_punctuation(aff.strip()).replace('  ',' ')  \n",
      "        aff = ' '.join([ word for word          # One source of variation in names it the\n",
      "                        in aff.split(' ')       #  inclusion of 'the'. We simply remove\n",
      "                        if word != 'the'] )     #  'the' from all names.\n",
      "        \n",
      "        if aff in institutions_lookup:          # In a previous step, we generated aggregation\n",
      "            aff = institutions_lookup[aff]      #  rules for some names. If there were multiple\n",
      "                                                #  similar names, this retrieves the most likely.\n",
      "        anames.append(aff)\n",
      "        \n",
      "        if aff not in institution_ids:\n",
      "            uri = 'http://history.archives.mbl.edu/concepts/institution/{0}'.format(uuid4())\n",
      "            institution_ids[aff] = uri            \n",
      "    return anames "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 389
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "location_ids = {}\n",
      "def get_location_uri(location):\n",
      "    if location not in location_ids:\n",
      "        uri = 'http://history.archives.mbl.edu/concepts/location/{0}'.format(uuid4())  \n",
      "        location_ids[location] = uri\n",
      "    else:\n",
      "        uri = location_ids[location]\n",
      "    return uri"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 416
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Generate cleaned data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cleaned_coursedata = []\n",
      "cleaned_locations = []\n",
      "cleaned_affiliations = []\n",
      "cleaned_coursegroups = []\n",
      "courses_added = set([])\n",
      "cleaned_investigators = []\n",
      "\n",
      "for datum in investigatorsdata:\n",
      "    try:\n",
      "        datum['Last Name']\n",
      "        datum['First Name']\n",
      "    except KeyError:\n",
      "        continue    \n",
      "    name, person_uri = normalized_person(datum['Last Name'], datum['First Name'])\n",
      "    last, first = name\n",
      "\n",
      "    try:\n",
      "        location = unidecode(datum['Location']).strip().lower()\n",
      "        location_uri = get_location_uri(location)\n",
      "    except KeyError:\n",
      "        location = ''\n",
      "    \n",
      "    try:\n",
      "        affiliation = datum['Affiliation']\n",
      "    except KeyError:\n",
      "        affiliation = None\n",
      "    \n",
      "    try:\n",
      "        role = unidecode(datum['Role'])\n",
      "    except KeyError:\n",
      "        role = ''   \n",
      "    try:\n",
      "        subject = unidecode(datum['Subject'])\n",
      "    except:\n",
      "        subject = ''\n",
      "        \n",
      "    try:\n",
      "        position = unidecode(datum['Position'])\n",
      "    except KeyError:\n",
      "        position = ''        \n",
      "        \n",
      "    # Person -[hasAffiliation:Position:Year]-> Affiliation\n",
      "    if affiliation is not None:    # Must have an affiliation.\n",
      "        for affname in normalized_institutions(affiliation):\n",
      "            aff_uri = institution_ids[affname]\n",
      "            cleaned_affiliation = {\n",
      "                'Person URI': person_uri,\n",
      "                'Last Name': last.title(),\n",
      "                'First Name': first.title(),\n",
      "                'Institution': affname.title(),\n",
      "                'Institution URI': aff_uri,\n",
      "                'Position': position,\n",
      "                'Year': datum['year'],\n",
      "            }\n",
      "            cleaned_affiliations.append(cleaned_affiliation)\n",
      "        \n",
      "    # Marine Biological Laboratory -[hasInvestigator:Role:Subject:Year]-> Person\n",
      "    cleaned_investigator = {\n",
      "        'Role': role.title(),\n",
      "        'Subject': subject.title(),\n",
      "        'Year': datum['year'],\n",
      "        'Person URI': person_uri,\n",
      "        'First Name': first.title(),\n",
      "        'Last Name': last.title(),\n",
      "    }\n",
      "    cleaned_investigators.append(cleaned_investigator)\n",
      "        \n",
      "for datum in coursedata:\n",
      "    try:\n",
      "        datum['Last Name']\n",
      "        datum['First Name']\n",
      "    except KeyError:\n",
      "        continue\n",
      "    name, person_uri = normalized_person(datum['Last Name'], datum['First Name'])\n",
      "    last, first = name\n",
      "        \n",
      "    try:\n",
      "        cname, coursegroup = normalize_coursename(datum['Course Name'])\n",
      "        cname = '{0} {1}'.format(cname, datum['year']).title()\n",
      "        coursegroup = coursegroup.title()\n",
      "        \n",
      "        course_uri = get_course_uri(cname)\n",
      "        coursegroup_uri = get_coursegroup_uri(coursegroup)\n",
      "    except KeyError:\n",
      "        cname = None\n",
      "        coursegroup = None\n",
      "        \n",
      "    try:\n",
      "        position = unidecode(datum['Position at Affiliation'])\n",
      "    except KeyError:\n",
      "        position = ''\n",
      "        \n",
      "    try:\n",
      "        location = unidecode(datum['Location']).strip().lower()\n",
      "        location_uri = get_location_uri(location)        \n",
      "    except KeyError:\n",
      "        location = ''\n",
      "    \n",
      "    try:\n",
      "        affiliation = datum['Affiliation']\n",
      "    except KeyError:\n",
      "        affiliation = None\n",
      "    \n",
      "    try:\n",
      "        role = unidecode(datum['Role'])\n",
      "    except KeyError:\n",
      "        role = ''\n",
      "        \n",
      "    # Course -[partOf:Year]-> Group\n",
      "    if cname not in courses_added:\n",
      "        cgroup_datum = {\n",
      "            'Course Group': coursegroup,\n",
      "            'Course Group URI': coursegroup_uri,\n",
      "            'Course Name': cname,            \n",
      "            'Course URI': course_uri,\n",
      "            'Year': datum['year'],\n",
      "        }\n",
      "        cleaned_coursegroups.append(cgroup_datum)\n",
      "        courses_added.add(cname)\n",
      "    \n",
      "    # Person -[hasLocation:Year]-> Location\n",
      "    cleaned_location = {\n",
      "        'Person URI': person_uri,\n",
      "        'Last Name': last.title(),\n",
      "        'First Name': first.title(),\n",
      "        'Location': location,    \n",
      "        'Location URI': location_uri,\n",
      "        'Year': datum['year'],\n",
      "    }\n",
      "    cleaned_locations.append(cleaned_location)\n",
      "    \n",
      "    # Person -[attended:Role:Year]-> Course\n",
      "    if cname is not None:   # Must have a course.\n",
      "        cleaned_datum = {\n",
      "            'Course Name': cname,\n",
      "            'Course URI': course_uri,\n",
      "            'Role': role,\n",
      "            'Person URI': person_uri,\n",
      "            'Last Name': last.title(),\n",
      "            'First Name': first.title(),\n",
      "            'Year': datum['year'],\n",
      "        }\n",
      "        cleaned_coursedata.append(cleaned_datum)\n",
      "    else:    # Person -[hasAffiliation:Position:Year]-> \"Marine Biological Laboratory\"\n",
      "        aff_uri = institution_ids[\"Marine Biological Laboratory\"]\n",
      "        cleaned_affiliation = {\n",
      "            'Person URI': person_uri,\n",
      "            'Last Name': last.title(),\n",
      "            'First Name': first.title(),\n",
      "            'Institution': 'Marine Biological Laboratory',\n",
      "            'Institution URI': aff_uri,\n",
      "            'Position': role,\n",
      "            'Year': datum['year'],\n",
      "        }\n",
      "    \n",
      "    # Person -[hasAffiliation:Position:Year]-> Affiliation\n",
      "    if affiliation is not None:    # Must have an affiliation.\n",
      "        for affname in normalized_institutions(affiliation):\n",
      "            aff_uri = institution_ids[affname]\n",
      "            cleaned_affiliation = {\n",
      "                'Person URI': person_uri,\n",
      "                'Last Name': last.title(),\n",
      "                'First Name': first.title(),\n",
      "                'Institution': affname.title(),\n",
      "                'Institution URI': aff_uri,\n",
      "                'Position': position,\n",
      "                'Year': datum['year'],\n",
      "            }\n",
      "            cleaned_affiliations.append(cleaned_affiliation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 423
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(coursedata), len(cleaned_coursedata), len(cleaned_affiliations), len(cleaned_coursegroups), len(cleaned_locations), len(cleaned_investigators)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "47813 46909 52500 1095 47248 7996\n"
       ]
      }
     ],
     "prompt_number": 418
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 315
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "headers = cleaned_coursedata[0].keys()\n",
      "with open('/Users/bpeirson/Desktop/MBL Data/cleaned_coursedata.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(headers)\n",
      "    for datum in cleaned_coursedata:\n",
      "        writer.writerow( [ datum[key] for key in headers ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 398
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "headers = cleaned_affiliations[0].keys()\n",
      "with open('/Users/bpeirson/Desktop/MBL Data/cleaned_affiliations.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(headers)\n",
      "    for datum in cleaned_affiliations:\n",
      "        writer.writerow( [ datum[key] for key in headers ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 424
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "headers = cleaned_coursegroups[0].keys()\n",
      "with open('/Users/bpeirson/Desktop/MBL Data/cleaned_coursegroups.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(headers)\n",
      "    for datum in cleaned_coursegroups:\n",
      "        writer.writerow( [ datum[key] for key in headers ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 407
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "headers = cleaned_locations[0].keys()\n",
      "with open('/Users/bpeirson/Desktop/MBL Data/cleaned_locations.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(headers)\n",
      "    for datum in cleaned_locations:\n",
      "        writer.writerow( [ datum[key] for key in headers ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 419
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "headers = cleaned_investigators[0].keys()\n",
      "with open('/Users/bpeirson/Desktop/MBL Data/cleaned_investigators.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(headers)\n",
      "    for datum in cleaned_investigators:\n",
      "        writer.writerow( [ datum[key] for key in headers ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 409
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/Users/bpeirson/Desktop/MBL Data/person.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(['Last Name', 'First Name', 'Person URI'])\n",
      "    for name, uri in person_ids.iteritems():\n",
      "        last,first = name\n",
      "        writer.writerow([last.title(), first.title(), uri])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 412
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/Users/bpeirson/Desktop/MBL Data/institution.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(['Institution', 'Institution URI'])\n",
      "    for institution, uri in institution_ids.iteritems():\n",
      "        writer.writerow([institution.title(), uri])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 414
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/Users/bpeirson/Desktop/MBL Data/location.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(['Location', 'Location URI'])\n",
      "    for location, uri in location_ids.iteritems():\n",
      "        writer.writerow([location, uri])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 420
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/Users/bpeirson/Desktop/MBL Data/course.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(['Course Name', 'Course URI'])\n",
      "    for cname, uri in course_ids.iteritems():\n",
      "        writer.writerow([cname, uri])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 421
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('/Users/bpeirson/Desktop/MBL Data/coursegroup.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(['Course Group', 'Course Group URI'])\n",
      "    for cname, uri in coursegroup_ids.iteritems():\n",
      "        writer.writerow([cname, uri])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 422
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}